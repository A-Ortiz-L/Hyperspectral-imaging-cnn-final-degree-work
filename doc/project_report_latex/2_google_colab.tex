\mbox{}


\chapter{Entrenamiento del modelo mediante Google Colab}
\label{ch:chapter2}
Uno de los parámetros más importantes dentro dentro del entrenamiento de modelos de deep learning es la velocidad.
La velocidad de entrenamiento es de vital importancia ya que los modelos pueden requerir entradas de tamaño masivo, por lo que la capacidad de cómputo
va a ser clave para acelerar este proceso y poder enfocarnos plenamente a la mejora del rendimiento de nuestro modelo, sin tener como cuello de botella la espera
que nos pueda producir volver a reentrenar el mismo con distintos parámetros.
De este modo podemos reajustar constantemente nuestro modelo para encontrar el punto óptimo de manera ágil.
En este trabajo vamos a entrenar nuestro modelo haciendo uso del framework de código abierto de Tensorflow, el cual incluye una API de deep learning llamada Keras, que será la que utilicemos.

El tipo de operaciones que requiere nuestra aplicación en la parte del tratamiento de imágenes y los propios procedimientos que realizan las redes neuronales
para hacer sus cálculos son operaciones matriciales.
Nuestro objetivo será aprovechar al máximo el rendimiento que una GPU nos puede dar en este tipo de operaciones gracias
a su arquitectura de paralelización, ya que es la idónea para este tipo de trabajo.
La ventaja que nos da frente a la cpu es la capacidad de cómputo, gracias a su conectividad por PCI express y el ancho de banda que esta proporciona.

https://www.nvidia.com/es-la/drivers/what-is-gpu-computing/

\section{Modelo propuesto}\label{sec:modelo-propuesto}
Modelo propuesto
\section{Entorno Google Colab}\label{sec:entorno-google-colab}
En esta parte del trabajo se pretende conseguir la máxima velocidad de entrenamiento posible manteniendo unos niveles de precisión elevados en la predicción.
La plataforma de Google Colab es un servicio gratuito de google, mediante el cual podemos ejecutar e instalar librerías del lenguaje de programación python.
La ventaja de hacer uso de este medio es podemos configurar nuestro entorno para hacer uso de de herramientas industriales tales como una GPU Tesla K80.
Las características principales de nuestro principal unidad de cómputo son las siguientes :

\begin{itemize}
\item 4992 núcleos de NVIDIA CUDA con diseño de dos GPU
\item Hasta 2,91 teraflops de rendimiento en operaciones de precisión doble con NVIDIA GPU Boost.
\item 24 GB de memoria GDDR5
\item 480 GB/s de ancho de banda de memoria agregado.
\item Hasta 8,73 teraflops de rendimiento en operaciones de precisión simple con NVIDIA GPU Boost.
\end{itemize}

Además, realizaremos algunas optimizaciones a nivel de hardware para acelerar el proceso de forma general.

\begin{itemize}
    \item \textbf{Uso de variables de 16 bits en vez de 32 bits}: Una de las posibilidades que nos brinda el uso de una GPU es reducir a la mitad el uso en memoria de las variables del proceso.
    Usaremos esto siempre y cuando no afecte al rendimiento en cuanto a predicción.
    \item \textbf{Uso del compilador XLA}: El compilador XLA (Accelerated Linear Algebra) optimiza el grafo de nuestro modelo de manera específica haciendo uso de la GPU.
    \item \textbf{Valores altos del parámetro de entrenamiento BatchSize}: Gracias a la capacidad de cómputo de nuestra tarjeta gráfica podemos permitirnos el uso de valores altos en este parámetro de entrenamiento.
\end{itemize}

El uso de este tipo de herramientas en esta plataforma es extrapolable a otras nubes sin las restricciones en cuanto al número de unidades de procesamiento que necesitamos,
la interoperabilidad de sus elementos con otros componentes externos, tales como servidores o respositorios de código y la configuración explícita de cada uno de los entornos de ejecución.